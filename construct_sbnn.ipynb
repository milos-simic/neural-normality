{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistic-Based Neural Network for Normality Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T18:30:39.025577Z",
     "start_time": "2021-04-27T18:30:30.194461Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import everything that's needed to run the notebook\n",
    "import os\n",
    "import pickle\n",
    "import pathlib\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from IPython.display import display, Markdown, Latex\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics\n",
    "import sklearn.preprocessing\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import boruta\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T18:30:39.063317Z",
     "start_time": "2021-04-27T18:30:39.027232Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the path to the configuration dictionary\n",
    "config_path = 'configuration.p'\n",
    "\n",
    "# Load the configuration dictionary\n",
    "with open(config_path, 'rb') as f:\n",
    "    configuration = pickle.load(f)\n",
    "    \n",
    "# Get the paths to the relevant directories \n",
    "data_directory_path = configuration['data']['directory_path']\n",
    "classifiers_directory_path = configuration['classifiers']['directory_path']\n",
    "\n",
    "# Get the parameters of the experiment\n",
    "cv_folds = configuration['experiment']['number_of_cv_folds']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "Load the datasets using the function `load_from_file` from `util`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T18:30:40.113409Z",
     "start_time": "2021-04-27T18:30:39.064765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading A from data/A.data\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Define the dictionary to store the actual datasets, indexed by their names\n",
    "datasets = {}\n",
    "\n",
    "# Load the datasets\n",
    "for set_name in ['A']:\n",
    "    set_path = configuration['data']['datasets'][set_name]['path']\n",
    "    print('Loading {} from {}'.format(set_name, set_path))\n",
    "    datasets[set_name] = util.load_from_file(set_path)\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split $\\mathcal{A}$ into Cross-validation and Test  Subsets ($\\mathcal{A}_{cv}$ and $\\mathcal{A}_{test}$) \n",
    "\n",
    "Split $\\mathcal{A}$ into the subsets for cross-validation ($\\mathcal{A}_{cv})$ and testing ($\\mathcal{A}_{test}$).\n",
    "\n",
    "Use 70% of the set to cross-validate and 30% for subsequent testing and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T18:30:42.794129Z",
     "start_time": "2021-04-27T18:30:42.473008Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the labels from the set, leaving only samples in it\n",
    "labels = [labeled_sample.pop() for labeled_sample in datasets['A']]\n",
    "samples = datasets['A']\n",
    "\n",
    "# There is no need to store the sama data twice, in datasets['A'] and in (samples, labels)\n",
    "del datasets['A']\n",
    "\n",
    "# Define the stratification labels as the combination of actual labels and sample sizes\n",
    "stratification_labels = [str(label) + str(len(sample)) for (label, sample) in zip(labels, samples)]\n",
    "\n",
    "# Set the relative size of the CV subset\n",
    "train_size = 0.7\n",
    "\n",
    "# Split the data into CV and test subsets\n",
    "set_A_cv, set_A_test, y_cv, y_test = train_test_split(samples, labels, stratify=stratification_labels, \n",
    "                                              train_size=train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the Statistic-based Feedforward Neural Network Classifier (SBNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T18:30:53.709893Z",
     "start_time": "2021-04-27T18:30:53.683341Z"
    }
   },
   "outputs": [],
   "source": [
    "def lin_mudholkar_statistic(sample, tol=1e-7):\n",
    "    n = len(sample)\n",
    "    sum_of_squares = 0\n",
    "    for x in sample:\n",
    "        sum_of_squares = sum_of_squares + x**2\n",
    "        \n",
    "    h_values = [0 for i in range(n)]\n",
    "    for i in range(n):\n",
    "        x = sample[i]\n",
    "        \n",
    "        corrected_sum = 0\n",
    "        for j in range(n):\n",
    "            if j != i:\n",
    "                corrected_sum = corrected_sum + sample[j]\n",
    "                \n",
    "        square_of_sum = corrected_sum**2\n",
    "        difference = (((sum_of_squares - x**2) - square_of_sum / (n - 1)) / n)\n",
    "        if abs(difference) <= tol:\n",
    "            difference = 0\n",
    "        h_i = difference**(1/3)\n",
    "        h_values[i] = h_i\n",
    "        \n",
    "        #print(i, x, corrected_sum, square_of_sum, square_of_sum / (n - 1), '\\n', h_i)\n",
    "    \n",
    "    r = np.corrcoef(sample, h_values)\n",
    "    \n",
    "    return np.arctan(r[0, 1])\n",
    "\n",
    "def vasicek_statistic(sample, m=3):\n",
    "    n = len(sample)\n",
    "    sample = np.array(sample, dtype=np.float64)\n",
    "    sd = np.std(sample)\n",
    "    sorted_sample = np.sort(sample)\n",
    "    product = 1\n",
    "    m = m\n",
    "    for i in range(n):\n",
    "        if i - m < 0:\n",
    "            left = sorted_sample[0]\n",
    "        else:\n",
    "            left = sorted_sample[i - m]\n",
    "        \n",
    "        if i + m > n - 1:\n",
    "            right = sorted_sample[n - 1]\n",
    "        else:\n",
    "            right = sorted_sample[i + m]\n",
    "        \n",
    "        product = product * (right - left)\n",
    "    \n",
    "    return (n / (2 * m * sd)) * (product ** (1 / n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T18:31:44.524793Z",
     "start_time": "2021-04-27T18:31:44.509335Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(sample : list[float]):\n",
    "    n = len(sample)\n",
    "    skewness = scipy.stats.skew(sample)\n",
    "    kurtosis = scipy.stats.kurtosis(sample, fisher=False)\n",
    "    W = scipy.stats.shapiro(sample).statistic\n",
    "    lm_stat = lin_mudholkar_statistic(sample)\n",
    "    K3 = vasicek_statistic(sample, m=3)\n",
    "    K5 = vasicek_statistic(sample, m=5)\n",
    "    return [skewness, kurtosis, W, lm_stat, K3, K5, n]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T18:31:46.851297Z",
     "start_time": "2021-04-27T18:31:46.844044Z"
    }
   },
   "outputs": [],
   "source": [
    "class SBNNPreprocessor(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        super(SBNNPreprocessor, self).__init__()\n",
    "        \n",
    "        # Set the names of the features in the descriptors\n",
    "        self.features = ['skewness', 'kurtosis', 'W', 'LN-statistic', 'K3', 'K5', 'n']\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Not needed, but present for compatibility.\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Note: Currently working only on a list of lists or a single list.\n",
    "        if isinstance(X, list):\n",
    "            if all(isinstance(x, list) for x in X):\n",
    "                X = [preprocess(x) for x in X]\n",
    "                return pd.DataFrame(X)\n",
    "            else:\n",
    "                X = preprocess(X)\n",
    "                return X\n",
    "        else:\n",
    "            # Pandas dataframes and numpy arrays are not supported for now.\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validate\n",
    "Create a `sklearn` pipeline that consists of the preprocessor, standard scaler, mean imputer to replace the null values, and the neural network itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T18:31:51.206246Z",
     "start_time": "2021-04-27T18:31:51.202790Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = SBNNPreprocessor()\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "neural_net = MLPClassifier(solver='adam', max_iter=200, activation='relu',\n",
    "                           early_stopping=True, validation_fraction=0.1)\n",
    "pipe = Pipeline([('preprocessor', preprocessor),\n",
    "                 ('scaler', scaler),\n",
    "                 ('imputer', imputer),\n",
    "                 ('neural_net', neural_net),\n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the grid search to fit the network's parameters and find the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T19:28:08.025648Z",
     "start_time": "2021-04-27T18:31:58.103568Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 100 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milos/statisticka_klasifikacija/p39normal/lib/python3.9/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.83990139 0.84028451 0.84542913 0.8448274  0.84630506 0.84701668\n",
      " 0.84685237 0.84854917 0.85008194 0.84926078 0.84696184 0.84843982\n",
      " 0.84997227 0.84718106 0.84893261 0.84712591 0.84761864 0.8482209\n",
      " 0.84969868 0.85002735 0.49994526 0.76129322 0.84909669 0.85068408\n",
      " 0.84915135 0.84548406 0.84521086 0.84504665 0.84816621 0.84729071\n",
      " 0.84411624 0.84915118 0.84937012 0.84937043 0.84915131 0.84772837\n",
      " 0.8486588  0.8514503  0.8505195  0.84926097 0.84646876 0.84783806\n",
      " 0.85024604 0.85057454 0.85024624 0.66985986 0.8476735  0.84756415\n",
      " 0.84718091 0.84920621        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/milos/statisticka_klasifikacija/p39normal/lib/python3.9/site-packages/numpy/lib/function_base.py:2642: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/milos/statisticka_klasifikacija/p39normal/lib/python3.9/site-packages/numpy/lib/function_base.py:2643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/home/milos/statisticka_klasifikacija/p39normal/lib/python3.9/site-packages/scipy/stats/morestats.py:1678: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "<ipython-input-5-1935c0bba518>:49: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return (n / (2 * m * sd)) * (product ** (1 / n))\n",
      "<ipython-input-5-1935c0bba518>:49: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (n / (2 * m * sd)) * (product ** (1 / n))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=Pipeline(steps=[('preprocessor', SBNNPreprocessor()),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('imputer', SimpleImputer()),\n",
       "                                       ('neural_net',\n",
       "                                        MLPClassifier(early_stopping=True))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'neural_net__activation': ['relu', 'spocu'],\n",
       "                         'neural_net__alpha': [1, 0.1],\n",
       "                         'neural_net__hidden_layer_sizes': [[5], [10], [20],\n",
       "                                                            [50], [100], [5, 5],\n",
       "                                                            [10, 1...,\n",
       "                                                            [50, 50],\n",
       "                                                            [100, 100],\n",
       "                                                            [5, 5, 5],\n",
       "                                                            [10, 10, 10],\n",
       "                                                            [20, 20, 20],\n",
       "                                                            [50, 50, 50],\n",
       "                                                            [100, 100, 100],\n",
       "                                                            [5, 5, 5, 5, 5],\n",
       "                                                            [10, 10, 10, 10,\n",
       "                                                             10],\n",
       "                                                            [20, 20, 20, 20,\n",
       "                                                             20],\n",
       "                                                            [50, 50, 50, 50,\n",
       "                                                             50],\n",
       "                                                            [100, 100, 100, 100,\n",
       "                                                             100],\n",
       "                                                            [5, 5, 5, 5, 5, 5,\n",
       "                                                             5, 5, 5, 5],\n",
       "                                                            [10, 10, 10, 10, 10,\n",
       "                                                             10, 10, 10, 10,\n",
       "                                                             10],\n",
       "                                                            [20, 20, 20, 20, 20,\n",
       "                                                             20, 20, 20, 20,\n",
       "                                                             20],\n",
       "                                                            [50, 50, 50, 50, 50,\n",
       "                                                             50, 50, 50, 50,\n",
       "                                                             50],\n",
       "                                                            [100, 100, 100, 100,\n",
       "                                                             100, 100, 100, 100,\n",
       "                                                             100, 100]]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the hyperparameter grid\n",
    "param_grid = dict(\n",
    "                  neural_net__hidden_layer_sizes = [\n",
    "                      [w for i in range(d)] for d in [1, 2, 3, 5, 10] \\\n",
    "                                            for w in [5, 10, 20, 50, 100]\n",
    "                  ],\n",
    "                  neural_net__alpha = [1, 0.1],\n",
    "                  neural_net__activation =  ['relu', 'spocu']\n",
    "                 )\n",
    "\n",
    "# Define the grid search object\n",
    "grid = GridSearchCV(pipe,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='accuracy',\n",
    "                    refit=True,\n",
    "                    cv=cv_folds,\n",
    "                    verbose=1,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "# Perform cross-validation\n",
    "grid.fit(set_A_cv, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T19:28:08.035100Z",
     "start_time": "2021-04-27T19:28:08.029159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neural_net__activation': 'relu',\n",
       " 'neural_net__alpha': 0.1,\n",
       " 'neural_net__hidden_layer_sizes': [20, 20, 20]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the trained network.\n",
    "sbnn = grid.best_estimator_\n",
    "\n",
    "# Show its hyperparameters\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T19:28:08.762627Z",
     "start_time": "2021-04-27T19:28:08.036967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structure</th>\n",
       "      <th>activation</th>\n",
       "      <th>c</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>score_sd</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>time_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5]</td>\n",
       "      <td>relu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.839901</td>\n",
       "      <td>0.005030</td>\n",
       "      <td>46.003418</td>\n",
       "      <td>0.974525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[10]</td>\n",
       "      <td>relu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.840285</td>\n",
       "      <td>0.009808</td>\n",
       "      <td>45.301944</td>\n",
       "      <td>1.199483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[20]</td>\n",
       "      <td>relu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.845429</td>\n",
       "      <td>0.006311</td>\n",
       "      <td>65.558077</td>\n",
       "      <td>2.498080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[50]</td>\n",
       "      <td>relu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844827</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>65.463684</td>\n",
       "      <td>2.643042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[100]</td>\n",
       "      <td>relu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.846305</td>\n",
       "      <td>0.004892</td>\n",
       "      <td>74.791842</td>\n",
       "      <td>2.569304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]</td>\n",
       "      <td>spocu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.302210</td>\n",
       "      <td>0.398922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]</td>\n",
       "      <td>spocu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.935639</td>\n",
       "      <td>0.795542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[20, 20, 20, 20, 20, 20, 20, 20, 20, 20]</td>\n",
       "      <td>spocu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.931790</td>\n",
       "      <td>1.000703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[50, 50, 50, 50, 50, 50, 50, 50, 50, 50]</td>\n",
       "      <td>spocu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.104878</td>\n",
       "      <td>1.699192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[100, 100, 100, 100, 100, 100, 100, 100, 100, ...</td>\n",
       "      <td>spocu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.582458</td>\n",
       "      <td>5.805243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            structure activation    c  \\\n",
       "0                                                 [5]       relu  1.0   \n",
       "1                                                [10]       relu  1.0   \n",
       "2                                                [20]       relu  1.0   \n",
       "3                                                [50]       relu  1.0   \n",
       "4                                               [100]       relu  1.0   \n",
       "..                                                ...        ...  ...   \n",
       "95                     [5, 5, 5, 5, 5, 5, 5, 5, 5, 5]      spocu  0.1   \n",
       "96           [10, 10, 10, 10, 10, 10, 10, 10, 10, 10]      spocu  0.1   \n",
       "97           [20, 20, 20, 20, 20, 20, 20, 20, 20, 20]      spocu  0.1   \n",
       "98           [50, 50, 50, 50, 50, 50, 50, 50, 50, 50]      spocu  0.1   \n",
       "99  [100, 100, 100, 100, 100, 100, 100, 100, 100, ...      spocu  0.1   \n",
       "\n",
       "    mean_score  score_sd  mean_time   time_sd  \n",
       "0     0.839901  0.005030  46.003418  0.974525  \n",
       "1     0.840285  0.009808  45.301944  1.199483  \n",
       "2     0.845429  0.006311  65.558077  2.498080  \n",
       "3     0.844827  0.005242  65.463684  2.643042  \n",
       "4     0.846305  0.004892  74.791842  2.569304  \n",
       "..         ...       ...        ...       ...  \n",
       "95         NaN       NaN  50.302210  0.398922  \n",
       "96         NaN       NaN  50.935639  0.795542  \n",
       "97         NaN       NaN  50.931790  1.000703  \n",
       "98         NaN       NaN  50.104878  1.699192  \n",
       "99         NaN       NaN  33.582458  5.805243  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the means and deviations of the score(s) and CV time\n",
    "params = grid.cv_results_['params']\n",
    "mean_scores = grid.cv_results_['mean_test_score']\n",
    "score_sds = grid.cv_results_['std_test_score']\n",
    "mean_fit_times = grid.cv_results_['mean_fit_time']\n",
    "time_sds = grid.cv_results_['std_fit_time']\n",
    "\n",
    "results = []\n",
    "for (params, mean_score, score_sd, mean_fit_time, time_sd) in zip(params, mean_scores, score_sds, mean_fit_times, time_sds):\n",
    "    alpha = params['neural_net__alpha']\n",
    "    structure = params['neural_net__hidden_layer_sizes']\n",
    "    activation = params['neural_net__activation']\n",
    "    results.append([str(structure), activation, alpha, mean_score, score_sd, mean_fit_time, time_sd])\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = ['structure', 'activation', 'c', \n",
    "                      'mean_score', 'score_sd', 'mean_time', 'time_sd']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the SBNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T20:30:43.655879Z",
     "start_time": "2021-04-27T20:30:43.499698Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(classifiers_directory_path + '/sbnn.p', 'wb') as f:\n",
    "    pickle.dump(sbnn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p39n",
   "language": "python",
   "name": "p39n"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "247.067px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
