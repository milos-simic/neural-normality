{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate several sets of normal and non-normal samples <a class=\"tocSkip\">\n",
    "\n",
    "In this notebook, we create several datasets consisting of normal and non-normal samples. The simulated sets are named $\\mathcal{A}-\\mathcal{E}$. The real-world sets are named $\\mathcal{R}_{height}$ and $\\mathcal{R}_{earthquake}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:47:23.979933Z",
     "start_time": "2020-11-02T12:47:23.967952Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import util\n",
    "from ipynb.fs.defs.descriptor_based_neural_networks import traverse_and_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:43:25.536413Z",
     "start_time": "2020-11-02T12:43:25.428944Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the path to the configuration dictionary\n",
    "config_path = 'configuration.p'\n",
    "\n",
    "# Load the configuration dictionary\n",
    "with open(config_path, 'rb') as f:\n",
    "    configuration = pickle.load(f)\n",
    "    \n",
    "# Get the path to the directory to which the datasets will be stored\n",
    "data_directory_path = configuration['data']['directory_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set $\\mathcal{A}$\n",
    "\n",
    "The samples consist of $10, 20, \\ldots, 100$ elements. \n",
    "\n",
    "The normal samples are drawn from a a normal distributions $N(\\mu,\\sigma^2)$ whose location parameter ($\\mu$) is randomly selected from the range $[-100,100]$ and the standard deviation is randomly drawn from the range $[1, 20]$. For each $n$, a total of $L$ normal distributions are defined and a sample of size $n$ is drawn from each of them.\n",
    "\n",
    "The non-normal samples are drawn from the Pearson family of distributions. Each distribution is specified by its first four moments. The mean and standard deviation are determined the same as for the normal samples. They are combined with the skewness ($s$) and kurtosis ($k$) that range over $\\{\\}$ and $\\{\\}$ and fulfill the following two conditions: (1) $k - s^2 - 1 \\geq 0$ and (2) $\\neg(s=0 \\land k=3)$. The first condition is a limitation known from theory. The second requirement is there to ensure that those non-normal distributions are sufficiently different from the normal ones, since for normal distributions it holds that $s = 0$ and $k = 3$. A sample is drawn from each such distribution.\n",
    "\n",
    "The set is balanced. It contains $13050$ normal and $13050$ non-normal samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:43:38.615474Z",
     "start_time": "2020-11-02T12:43:38.605973Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the ranges for the sample sizes \n",
    "# and non-normal skewness and kurtosis in the set A\n",
    "n_range = range(10, 101, 10)\n",
    "s_range = [x/10.0 for x in range(-300, 301, 5)] # skewness range -300, 301, 5;-150, 151, 5;-805, 810, 5\n",
    "k_range = [x/10.0 for x in range(0, 401, 5)]   # kurtosis range 0, 401, 5;0, 201, 5;0, 1610, 5\n",
    "\n",
    "# Let M denote the number of non-normal samples drawn from the same distribution.\n",
    "# Since the set is created as balanced, M will influence the number of normal samples\n",
    "# in the set. See the function generate_dataset for details.\n",
    "M = 1\n",
    "\n",
    "# Create a function that generates datasets\n",
    "def generate_dataset(n_range, s_range, k_range, M, verbose=True):\n",
    "    # Generate non-normal samples\n",
    "    nonnormal_samples = util.generate_pearson_nonnormal_samples(s_range, k_range, n_range, M)\n",
    "\n",
    "    # Calculate L, the number of normal samples of the same size\n",
    "    L = len(nonnormal_samples) // len(n_range)\n",
    "            \n",
    "    # Generate L normal samples of size n for each n in n_range\n",
    "    normal_samples = util.generate_normal_samples(n_range, L)\n",
    "\n",
    "    # Print how many samples were generated\n",
    "    if verbose:\n",
    "        print(\"Normal samples: \", len(normal_samples))\n",
    "        print(\"Non-normal samples: \", len(nonnormal_samples))\n",
    "\n",
    "    # Label the sets\n",
    "    normal_samples = util.label_samples(normal_samples, 1)\n",
    "    nonnormal_samples = util.label_samples(nonnormal_samples, 0)\n",
    "\n",
    "    # Unify them\n",
    "    all_samples = normal_samples + nonnormal_samples\n",
    "    \n",
    "    return all_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:43:49.302395Z",
     "start_time": "2020-11-02T12:43:39.076440Z"
    }
   },
   "outputs": [],
   "source": [
    "set_A = generate_dataset(n_range, s_range, k_range, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the dataset, update the configuration dictionary, and save the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:43:59.221620Z",
     "start_time": "2020-11-02T12:43:59.204199Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function to describe the set, save it and update the configuration dictionary\n",
    "def describe_and_save(all_samples, set_name, n_range):\n",
    "    global data_directory_path\n",
    "    global configuration\n",
    "    \n",
    "    # Describe the set\n",
    "    metadata = {\n",
    "        'name' : set_name,\n",
    "        'n_range' : n_range,\n",
    "        'number_of_normal' : len([sample for sample in all_samples if sample[-1] == 1]),\n",
    "        'number_of_nonnormal' : len([sample for sample in all_samples if sample[-1] == 0]),\n",
    "        'path' : os.path.join(data_directory_path, '{}.data'.format(set_name))\n",
    "    }\n",
    "\n",
    "    # Add it to the configuration dictionary\n",
    "    configuration['data']['datasets'][set_name] = metadata\n",
    "\n",
    "    # Save the set to a file\n",
    "    path = metadata['path']\n",
    "    util.save_to_file(all_samples, path)\n",
    "    print(\"Saved to the file\", path)\n",
    "\n",
    "describe_and_save(set_A, 'A', n_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:44:06.645477Z",
     "start_time": "2020-11-02T12:44:06.636946Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function that calculates the skewness, kurtosis and standard deviation of each sample\n",
    "# in a given set of samples\n",
    "def inspect_dataset(samples):\n",
    "    dimensions = ['skewness', 'kurtosis', 'standard_deviation']\n",
    "    desc = {label: {dimension : [] for dimension in dimensions} for label in [0, 1]}\n",
    "\n",
    "    for i in range(len(samples)):\n",
    "        sample = samples[i][:-1]\n",
    "        label = samples[i][-1]\n",
    "        skewness = stats.skew(sample)\n",
    "        kurtosis = stats.kurtosis(sample, fisher=False)\n",
    "        sd = stats.tstd(sample)\n",
    "        desc[label]['skewness'].append(skewness)\n",
    "        desc[label]['kurtosis'].append(kurtosis)\n",
    "        desc[label]['standard_deviation'].append(sd)\n",
    "    \n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:44:16.491687Z",
     "start_time": "2020-11-02T12:44:07.438392Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inspect set A\n",
    "desc_A = inspect_dataset(set_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:44:21.398621Z",
     "start_time": "2020-11-02T12:44:20.471918Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the skewness and kurtosis of normal and non-normal sampes in set A\n",
    "\n",
    "colors = ['crimson', 'navy']\n",
    "for label in desc_A:\n",
    "    #ax = Axes3D(fig)\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(desc_A[label]['skewness'], \n",
    "                desc_A[label]['kurtosis'], alpha=0.2, color=colors[label])\n",
    "                #desc[label]['standard_deviation'])\n",
    "    #plt.xlim(-2, 2)\n",
    "    #plt.ylim(0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set $\\mathcal{B}$\n",
    "\n",
    "This set differs from $\\mathcal{A}$ only in the sizes of the samples. They contain contain $5, 15, \\ldots, 95$ elements. Everything else is completely the same as in the set $\\mathcal{A}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:46:00.055271Z",
     "start_time": "2020-09-23T23:45:50.379133Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the ranges for the sample sizes \n",
    "# and non-normal skewness and kurtosis in the set A\n",
    "n_range = range(5, 101, 10) \n",
    "s_range = [x/10.0 for x in range(-300, 301, 5)] # skewness range -150, 151, 5;-805, 810, 5\n",
    "k_range = [x/10.0 for x in range(0, 401, 5)]   # kurtosis range 0, 201, 5;0, 1610, 5\n",
    "\n",
    "# Let M denote the number of non-normal samples drawn from the same distribution\n",
    "M = 1\n",
    "\n",
    "set_B = generate_dataset(n_range, s_range, k_range, M)\n",
    "describe_and_save(set_B, 'B', n_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set $\\mathcal{C}$\n",
    "\n",
    "This set contains non-normal samples whose sizes are $10, 20, \\ldots, 100$.\n",
    "\n",
    "The non-normal distributions from which the samples are drawn are hand-picked and are usually used to assess the empirical power of normality tests. They are clssified into four groups. $G_1, G_2, G_3$ and $G_4$. See the paper for more details. For each sample size $n \\in \\left\\{10, 20, \\ldots, 100\\right\\}$, $L=10000$ samples are drawn from each group.\n",
    "\n",
    "Define the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:46:00.073569Z",
     "start_time": "2020-09-23T23:46:00.056534Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the distributions from group G1\n",
    "logistic = lambda n: stats.logistic.rvs(size = n)\n",
    "laplace = lambda n: stats.laplace.rvs(size = n)\n",
    "t1 = lambda n: stats.t.rvs(1, size = n)\n",
    "t3 = lambda n: stats.t.rvs(3, size = n)\n",
    "\n",
    "# Define the distributions from group G2\n",
    "gumbel1 = lambda n: list(np.random.gumbel(loc=0, scale=1, size=n))\n",
    "gumbel2 = lambda n: list(np.random.gumbel(loc=0, scale=2, size=n))\n",
    "gumbel3 = lambda n: list(np.random.gumbel(loc=0, scale=0.5, size=n))\n",
    "\n",
    "# Define the distributions from group G3\n",
    "expon = lambda n: stats.expon.rvs(loc = 1, size = n)\n",
    "gamma1 = lambda n: list(np.random.gamma(2, scale = 1, size = n))\n",
    "gamma2 = lambda n: list(np.random.gamma(0.5, scale = 1, size = n))\n",
    "lognormal1 = lambda n: list(np.random.lognormal(mean = 0, sigma = 1, size = n))\n",
    "lognormal2 = lambda n: list(np.random.lognormal(mean = 0, sigma = 2, size = n))\n",
    "lognormal3 = lambda n: list(np.random.lognormal(mean = 0, sigma = 0.5, size = n))\n",
    "weibull1 = lambda n: stats.weibull_min.rvs(0.5, scale = 1, size = n)\n",
    "weibull2 = lambda n: stats.weibull_min.rvs(2, scale = 1, size = n)\n",
    "\n",
    "# Define the distributions from group G4\n",
    "uniform = lambda n: list(np.random.uniform(low = 0, high = 1, size = n))\n",
    "beta1 = lambda n: np.random.beta(2, 2, size = n)\n",
    "beta2 = lambda n: np.random.beta(0.5, 0.5, size = n)\n",
    "beta3 = lambda n: np.random.beta(3, 1.5, size = n)\n",
    "beta4 = lambda n: np.random.beta(2, 1, size = n)\n",
    "\n",
    "# Let groups be a dictionary containing distributions from four groups G1-G4\n",
    "groups = {\n",
    "    1 : [logistic, laplace, t1, t3],\n",
    "    2 : [gumbel1, gumbel2, gumbel3],\n",
    "    3 : [expon, gamma1, gamma2, lognormal1, lognormal2, lognormal3, weibull1, weibull2],\n",
    "    4 : [uniform, beta1, beta2, beta3, beta4]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the set, save it and update the configuration dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:46:33.242795Z",
     "start_time": "2020-09-23T23:46:02.754033Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the range of sample sizes\n",
    "n_range = range(10, 101, 10)\n",
    "\n",
    "# Define L, which denotes how many samples with n elements\n",
    "# will be drawn from each group.\n",
    "L = 10000\n",
    "\n",
    "set_C = {}\n",
    "\n",
    "for g in groups:\n",
    "    # Select a group\n",
    "    group = groups[g]\n",
    "    \n",
    "    # Prepare the storage to hold the samples from this group\n",
    "    samples = []\n",
    "    \n",
    "    # Draw the samples\n",
    "    for n in n_range:\n",
    "        # Initialize the counter of the samples generated so far in this group\n",
    "        so_far = 0\n",
    "        \n",
    "        # Iterate over the distributions in the group until L samples are generated\n",
    "        d = 0\n",
    "        while so_far <= L:\n",
    "            # Get the distribution whose turn is to generate a sample\n",
    "            dist = group[d]\n",
    "            \n",
    "            # Generate a sample\n",
    "            sample = dist(n)\n",
    "            \n",
    "            # Store it\n",
    "            samples.append(sample)\n",
    "            \n",
    "            # Increase the counters\n",
    "            so_far = so_far + 1\n",
    "            d = d + 1\n",
    "            \n",
    "            # Return to the first distribution in the group and start over\n",
    "            if d == len(group):\n",
    "                d = 0\n",
    "    \n",
    "    # Label the samples as non-normal\n",
    "    samples = util.label_samples(samples, 0)\n",
    "    \n",
    "    # Describe the set\n",
    "    set_name = 'C-G{}'.format(g)\n",
    "    filename = '{}.data'.format(set_name)\n",
    "    \n",
    "    group_metadata = {\n",
    "        'name' : set_name,\n",
    "        'n_range' : n_range,\n",
    "        'number_of_normal' : 0,\n",
    "        'number_of_nonnormal' : len(samples),\n",
    "        'path' : os.path.join(data_directory_path, filename)\n",
    "    }\n",
    "\n",
    "    # Add it to the configuration dictionary\n",
    "    configuration['data']['datasets'][set_name] = group_metadata\n",
    "                \n",
    "    # Save the samples\n",
    "    path = group_metadata['path']\n",
    "    util.save_to_file(samples, path)\n",
    "    print(\"Saved {} to the file {}\".format(set_name, path))\n",
    "    \n",
    "    set_C[set_name] = samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the empirical skewness and kurtosis of the samples drawn from the four groups in set $\\mathcal{C}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:49:42.908323Z",
     "start_time": "2020-09-23T23:46:33.246474Z"
    }
   },
   "outputs": [],
   "source": [
    "for group_name in set_C:\n",
    "    desc = inspect_dataset(set_C[group_name])\n",
    "    for label in desc:\n",
    "        if label == 0:\n",
    "            fig = plt.figure()\n",
    "            plt.scatter(desc[label]['skewness'],\n",
    "                        desc[label]['kurtosis'],\n",
    "                        alpha=0.2,\n",
    "                        color='crimson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set $\\mathcal{D}$\n",
    "\n",
    "Create it the same way as the set $\\mathcal{A}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:49:56.733860Z",
     "start_time": "2020-09-23T23:49:42.910519Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the ranges for the sample sizes \n",
    "# and non-normal skewness and kurtosis \n",
    "n_range = range(10, 101, 10)\n",
    "s_range = [x/10.0 for x in range(-300, 301, 5)] # skewness range -150, 151, 5;-805, 810, 5\n",
    "k_range = [x/10.0 for x in range(0, 401, 5)]   # kurtosis range 0, 201, 5;0, 1610, 5\n",
    "\n",
    "# Let M denote the number of non-normal samples drawn from the same distribution.\n",
    "# Since the set is created as balanced, M will influence the number of normal samples\n",
    "# in the set. See the function generate_dataset for details.\n",
    "M = 1\n",
    "\n",
    "# Generate and register the set\n",
    "set_D = generate_dataset(n_range, s_range, k_range, M)\n",
    "describe_and_save(set_D, 'D', n_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set $\\mathcal{E}$\n",
    "\n",
    "Generate it the same way as $\\mathcal{A}$, but with more samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:51:02.014304Z",
     "start_time": "2020-09-23T23:49:56.741387Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the ranges for the sample sizes \n",
    "# and non-normal skewness and kurtosis \n",
    "n_range = range(10, 101, 10)\n",
    "s_range = [x/10.0 for x in range(-300, 301, 5)] # skewness range -150, 151, 5;-805, 810, 5\n",
    "k_range = [x/10.0 for x in range(0, 401, 5)]   # kurtosis range 0, 201, 5;0, 1610, 5\n",
    "\n",
    "# Let M denote the number of non-normal samples drawn from the same distribution.\n",
    "# Since the set is created as balanced, M will influence the number of normal samples\n",
    "# in the set. See the function generate_dataset for details.\n",
    "M = 5\n",
    "\n",
    "# Generate and register the set\n",
    "set_E = generate_dataset(n_range, s_range, k_range, M)\n",
    "describe_and_save(set_E, 'E', n_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Datasets\n",
    "\n",
    "### Set $\\mathcal{R}_{height}$\n",
    "The original data were taken from https://github.com/rmcelreath/rethinking/blob/master/data/Howell1.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:47:54.037970Z",
     "start_time": "2020-11-02T12:47:54.021883Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('data/Howell1.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both sexes and each age window from $[18, 27]$ to $[79, 88]$, extract the corresponding heights from the original data and form a new sample of heights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:49:26.596987Z",
     "start_time": "2020-11-02T12:47:56.042410Z"
    }
   },
   "outputs": [],
   "source": [
    "figs = {}\n",
    "sex = ['female', 'male']\n",
    "\n",
    "age_limits = [(x, x + 9) for x in range(18, 80)]\n",
    "\n",
    "samples = {}\n",
    "\n",
    "for male in [0, 1]:\n",
    "    for (min_age, max_age) in age_limits:\n",
    "        mask = (df['male'] == male) & (df['age'] >= min_age) & (df['age'] < max_age)\n",
    "        \n",
    "        heights = list(df[mask]['height'].values)\n",
    "        samples[(male, min_age, max_age)] = heights\n",
    "        n = len(heights)\n",
    "        \n",
    "        description = df[mask]['height'].describe()\n",
    "        m = description['mean']\n",
    "        s = description['std']\n",
    "        \n",
    "        fig = plt.figure(figsize=(10, 7))\n",
    "        \n",
    "        #divergences = []\n",
    "\n",
    "        for i in range(100):\n",
    "            random_sample = np.random.normal(m, s, n)\n",
    "            density = stats.gaussian_kde(random_sample)\n",
    "            #divergence = stats.entropy(heights, random_sample)\n",
    "            #divergences.append(divergence)\n",
    "    \n",
    "            random_sample.sort()\n",
    "            plt.hist(random_sample, bins=10, color='lavender', density=True, cumulative=True,\n",
    "                      histtype='step', linewidth=3)\n",
    "\n",
    "        plt.hist(heights, bins=10, color='navy', density=True, cumulative=True, histtype='step', linewidth=3)\n",
    " \n",
    "        legend_objects = [Line2D([0], [0], color='navy', lw=3), Line2D([0], [0], color='lavender', lw=3)]\n",
    "        plt.legend(legend_objects, ['Original EDF', 'Simulated EDFs'], fontsize=13, loc='upper left')\n",
    "        plt.xlabel('Height (cm)')\n",
    "        figs[(male, min_age, max_age)] = fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label samples as normal and save them\n",
    "samples = util.label_samples(list(samples.values()), 1)\n",
    "\n",
    "describe_and_save(samples, 'R_height', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:50:47.143559Z",
     "start_time": "2020-11-02T12:49:26.598376Z"
    }
   },
   "outputs": [],
   "source": [
    "figs = {'{}_{}_{}_fig'.format(*key) : figs[key] for key in figs}\n",
    "\n",
    "traverse_and_save({ 'data' : {'R_height' : figs}},\n",
    "                  configuration['reports']['directory_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set $\\mathcal{R}_{earthquake}$\n",
    "\n",
    "The original data were taken from http://socr.ucla.edu/docs/resources/SOCR_Data/SOCR_Data_Earthquakes_Over3.html ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:51:40.749675Z",
     "start_time": "2020-11-02T12:51:40.464863Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('data/earthquakes.csv', header=0, parse_dates=[0], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:51:41.433778Z",
     "start_time": "2020-11-02T12:51:41.375176Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:51:51.649960Z",
     "start_time": "2020-11-02T12:51:50.929835Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the density of the magnitudes\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "df['Mag'].plot.density(linewidth=3, color='navy')\n",
    "plt.xlabel('Magnitude')\n",
    "traverse_and_save({ 'data' : {'R_earthquake' : {'magnitude_density_fig' : fig}}},\n",
    "                  configuration['reports']['directory_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T12:52:19.652944Z",
     "start_time": "2020-11-02T12:52:07.232230Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sample from the density (which is clearly not normal)\n",
    "# to create a number of non-normal samples\n",
    "\n",
    "samples = []\n",
    "\n",
    "n_range = range(5, 101, 5)\n",
    "\n",
    "for n in n_range:\n",
    "    for i in range(1000):\n",
    "        sample = list(df.sample(n=n)['Mag'].values)\n",
    "        samples.append(sample)\n",
    "        \n",
    "# Label the samples as non-normal\n",
    "samples = util.label_samples(samples, 0)\n",
    "\n",
    "# Save them\n",
    "describe_and_save(samples, 'R_earthquake', n_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the changes to the configuration dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:51:02.522099Z",
     "start_time": "2020-09-23T23:51:02.015613Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(config_path, 'wb') as f:\n",
    "    pickle.dump(configuration, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3normal",
   "language": "python",
   "name": "p3normal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
