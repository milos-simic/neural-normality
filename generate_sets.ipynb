{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate several sets of normal and non-normal samples <a class=\"tocSkip\">\n",
    "\n",
    "In this notebook, we create several datasets consisting of normal and non-normal samples. The simulated sets are named $\\mathcal{A}-\\mathcal{G}$. The real-world sets are named $\\mathcal{R}_{height}$ and $\\mathcal{R}_{earthquake}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T19:51:09.185935Z",
     "start_time": "2021-04-10T19:50:54.995437Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import util\n",
    "from ipynb.fs.defs.descriptor_based_neural_networks import traverse_and_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T19:51:09.222736Z",
     "start_time": "2021-04-10T19:51:09.187403Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the path to the configuration dictionary\n",
    "config_path = 'configuration.p'\n",
    "\n",
    "# Load the configuration dictionary if it exists\n",
    "with open(config_path, 'rb') as f:\n",
    "    configuration = pickle.load(f)\n",
    "    \n",
    "# Get the path to the directory to which the datasets will be stored\n",
    "data_directory_path = configuration['data']['directory_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary to store figures before saving them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T19:51:09.528963Z",
     "start_time": "2021-04-10T19:51:09.224825Z"
    }
   },
   "outputs": [],
   "source": [
    "figures = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set $\\mathcal{A}$\n",
    "\n",
    "The samples consist of $10, 20, \\ldots, 100$ elements. \n",
    "\n",
    "The normal samples are drawn from a a normal distributions $N(\\mu,\\sigma^2)$ whose location parameter ($\\mu$) is randomly selected from the range $[-100,100]$ and the standard deviation is randomly drawn from the range $[1, 20]$. For each $n$, a total of $L$ normal distributions are defined and a sample of size $n$ is drawn from each of them.\n",
    "\n",
    "The non-normal samples are drawn from the Pearson family of distributions. Each distribution is specified by its first four moments. The mean and standard deviation are determined the same as for the normal samples. They are combined with the skewness ($s$) and kurtosis ($k$) that range over $\\{\\}$ and $\\{\\}$ and fulfill the following two conditions: (1) $k - s^2 - 1 \\geq 0$ and (2) $\\neg(s=0 \\land k=3)$. The first condition is a limitation known from theory. The second requirement is there to ensure that those non-normal distributions are sufficiently different from the normal ones, since for normal distributions it holds that $s = 0$ and $k = 3$. A sample is drawn from each such distribution.\n",
    "\n",
    "The set is balanced. It contains $13050$ normal and $13050$ non-normal samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T19:51:24.291342Z",
     "start_time": "2021-04-10T19:51:24.275884Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function that generates datasets\n",
    "def generate_dataset(n_range, s_range, k_range, M, verbose=True):\n",
    "    # Generate non-normal samples\n",
    "    nonnormal_samples = util.generate_pearson_nonnormal_samples(s_range, k_range, n_range, M)\n",
    "\n",
    "    # Calculate L, the number of normal samples of the same size\n",
    "    L = len(nonnormal_samples) // len(n_range)\n",
    "            \n",
    "    # Generate L normal samples of size n for each n in n_range\n",
    "    normal_samples = util.generate_normal_samples(n_range, L)\n",
    "\n",
    "    # Print how many samples were generated\n",
    "    if verbose:\n",
    "        print(\"Normal samples: \", len(normal_samples))\n",
    "        print(\"Non-normal samples: \", len(nonnormal_samples))\n",
    "\n",
    "    # Label the sets\n",
    "    normal_samples = util.label_samples(normal_samples, 1)\n",
    "    nonnormal_samples = util.label_samples(nonnormal_samples, 0)\n",
    "\n",
    "    # Unify them\n",
    "    all_samples = normal_samples + nonnormal_samples\n",
    "    \n",
    "    return all_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T17:29:13.432739Z",
     "start_time": "2021-04-09T17:29:13.421850Z"
    }
   },
   "source": [
    "Use the function from the above cell to create dataset $\\mathcal{A}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T12:39:48.680867Z",
     "start_time": "2021-04-10T12:39:39.177674Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the ranges for the sample sizes \n",
    "# and non-normal skewness and kurtosis in the set A\n",
    "n_range = range(10, 101, 10)\n",
    "s_range = [x/10.0 for x in range(-300, 301, 5)] # skewness range -300, 301, 5;-150, 151, 5;-805, 810, 5\n",
    "k_range = [x/10.0 for x in range(0, 401, 5)]   # kurtosis range 0, 401, 5;0, 201, 5;0, 1610, 5\n",
    "\n",
    "# Let M denote the number of non-normal samples drawn from the same distribution.\n",
    "# Since the set is created as balanced, M will influence the number of normal samples\n",
    "# in the set too. See the function generate_dataset for details.\n",
    "M = 1\n",
    "\n",
    "# Generate set A\n",
    "set_A = generate_dataset(n_range, s_range, k_range, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the dataset, update the configuration dictionary, and save the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T19:51:33.588643Z",
     "start_time": "2021-04-10T19:51:33.573507Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function to describe the set, save it and update the configuration dictionary\n",
    "def describe_and_save(all_samples, set_name, n_range):\n",
    "    global data_directory_path\n",
    "    global configuration\n",
    "    \n",
    "    # Describe the set\n",
    "    metadata = {\n",
    "        'name' : set_name,\n",
    "        'n_range' : n_range,\n",
    "        'number_of_normal' : len([sample for sample in all_samples if sample[-1] == 1]),\n",
    "        'number_of_nonnormal' : len([sample for sample in all_samples if sample[-1] == 0]),\n",
    "        'path' : os.path.join(data_directory_path, '{}.data'.format(set_name))\n",
    "    }\n",
    "\n",
    "    # Add it to the configuration dictionary\n",
    "    configuration['data']['datasets'][set_name] = metadata\n",
    "\n",
    "    # Save the set to a file\n",
    "    path = metadata['path']\n",
    "    util.save_to_file(all_samples, path)\n",
    "    print(\"Saved to the file\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T12:41:01.956137Z",
     "start_time": "2021-04-10T12:41:00.967553Z"
    }
   },
   "outputs": [],
   "source": [
    "describe_and_save(set_A, 'A', n_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the functions for visualizing selected sample statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T12:47:36.201987Z",
     "start_time": "2021-04-10T12:47:36.184895Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the function that can estimate certain sample statistics such as standard deviation, skewness, kurtosis\n",
    "# and so on.\n",
    "def calculate(sample, statistic):\n",
    "    if statistic == 'sd':\n",
    "        return stats.tstd(sample)\n",
    "    elif statistic == 'skewness':\n",
    "        return stats.skew(sample)\n",
    "    elif statistic == 'kurtosis':\n",
    "        return stats.kurtosis(sample)\n",
    "    elif statistic == 'mad':\n",
    "        return stats.median_abs_deviation(sample)\n",
    "    elif statistic == 'rkurtosis':\n",
    "        # robust kurtosis\n",
    "        median = np.median(sample)\n",
    "        robust_moment = stats.median_abs_deviation([(median - x)**4 for x in sample])\n",
    "        mad = stats.median_abs_deviation(sample)\n",
    "        return robust_moment / max(mad**4, 0.1**8)\n",
    "    elif statistic == 'rskewness':\n",
    "        # robust skewness\n",
    "        median = np.median(sample)\n",
    "        robust_moment = stats.median_abs_deviation([(median - x)**3 for x in sample])\n",
    "        mad = stats.median_abs_deviation(sample)\n",
    "        return robust_moment / max(mad**3, 0.1**8)\n",
    "    elif statistic == 'm5':\n",
    "        sd = stats.tstd(sample)\n",
    "        m5 = stats.moment(sample, moment=5)\n",
    "        return m5/max(sd**5, 0.1**8)\n",
    "    elif statistic == 'm6':\n",
    "        sd = stats.tstd(sample)\n",
    "        m5 = stats.moment(sample, moment=6)\n",
    "        return m5/max(sd**6, 0.1**8)\n",
    "    elif statistic == 'm7':\n",
    "        sd = stats.tstd(sample)\n",
    "        m5 = stats.moment(sample, moment=7)\n",
    "        return m5/max(sd**7, 0.1**8)\n",
    "\n",
    "# Create a function that calculates selected statistics of each sample in a given set of samples\n",
    "def inspect_dataset(samples, labels=None, statistics=['skewness', 'kurtosis']):\n",
    "    desc = {label: {statistic : [] for statistic in statistics} for label in [0, 1]}\n",
    "\n",
    "    for i in range(len(samples)):\n",
    "        if labels is None:\n",
    "            sample = samples[i][:-1]\n",
    "            label = samples[i][-1]\n",
    "        else:\n",
    "            sample = samples[i]\n",
    "            label = labels[i]\n",
    "        \n",
    "        for statistic in statistics:\n",
    "            desc[label][statistic].append(calculate(sample, statistic))\n",
    "    \n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T12:47:46.927331Z",
     "start_time": "2021-04-10T12:47:37.863255Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inspect set A\n",
    "desc_A = inspect_dataset(set_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T12:50:57.488674Z",
     "start_time": "2021-04-10T12:50:57.481094Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the skewness and kurtosis of normal and non-normal sampes in set A\n",
    "\n",
    "# Define a function for plotting\n",
    "def plot_skewness_and_kurtosis(data_desc):\n",
    "    colors = ['crimson', 'navy']\n",
    "    figs = {}\n",
    "    for label in data_desc:\n",
    "        #ax = Axes3D(fig)\n",
    "        if len(data_desc[label]['skewness']) > 0:\n",
    "            fig = plt.figure(figsize=(10, 7))\n",
    "            plt.scatter(data_desc[label]['skewness'], \n",
    "                        data_desc[label]['kurtosis'], alpha=0.2, color=colors[label])\n",
    "                        #desc[label]['standard_deviation'])\n",
    "            #plt.xlim(-2, 2)\n",
    "            #plt.ylim(0, 10)\n",
    "            figs[label] = fig\n",
    "    return figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T12:53:20.560949Z",
     "start_time": "2021-04-10T12:53:18.571124Z"
    }
   },
   "outputs": [],
   "source": [
    "figs = plot_skewness_and_kurtosis(desc_A)\n",
    "figures['A'] = figs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set $\\mathcal{B}$\n",
    "\n",
    "This set differs from $\\mathcal{A}$ only in the sizes of the samples. They contain contain $5, 15, \\ldots, 95$ elements. Everything else is completely the same as in the set $\\mathcal{A}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T12:53:42.321581Z",
     "start_time": "2021-04-10T12:53:33.294240Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the ranges for the sample sizes \n",
    "# and non-normal skewness and kurtosis in the set A\n",
    "n_range = range(5, 101, 10) \n",
    "s_range = [x/10.0 for x in range(-300, 301, 5)] # skewness range -150, 151, 5;-805, 810, 5\n",
    "k_range = [x/10.0 for x in range(0, 401, 5)]   # kurtosis range 0, 201, 5;0, 1610, 5\n",
    "\n",
    "# Let M denote the number of non-normal samples drawn from the same distribution\n",
    "M = 1\n",
    "\n",
    "set_B = generate_dataset(n_range, s_range, k_range, M)\n",
    "describe_and_save(set_B, 'B', n_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T12:53:51.399300Z",
     "start_time": "2021-04-10T12:53:42.323414Z"
    }
   },
   "outputs": [],
   "source": [
    "figs = plot_skewness_and_kurtosis(inspect_dataset(set_B))\n",
    "figures['B'] = figs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set $\\mathcal{C}$\n",
    "\n",
    "This set contains non-normal samples whose sizes are $10, 20, \\ldots, 100$.\n",
    "\n",
    "The non-normal distributions from which the samples are drawn are hand-picked and are usually used to assess the empirical power of normality tests. They are clssified into four groups. $G_1, G_2, G_3$ and $G_4$. See the paper for more details. For each sample size $n \\in \\left\\{10, 20, \\ldots, 100\\right\\}$, $L=10000$ samples are drawn from each group.\n",
    "\n",
    "Define the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T12:53:51.410168Z",
     "start_time": "2021-04-10T12:53:51.400843Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the distributions from group G1\n",
    "logistic = lambda n: stats.logistic.rvs(size = n)\n",
    "laplace = lambda n: stats.laplace.rvs(size = n)\n",
    "t1 = lambda n: stats.t.rvs(1, size = n)\n",
    "t3 = lambda n: stats.t.rvs(3, size = n)\n",
    "\n",
    "# Define the distributions from group G2\n",
    "gumbel1 = lambda n: list(np.random.gumbel(loc=0, scale=1, size=n))\n",
    "gumbel2 = lambda n: list(np.random.gumbel(loc=0, scale=2, size=n))\n",
    "gumbel3 = lambda n: list(np.random.gumbel(loc=0, scale=0.5, size=n))\n",
    "\n",
    "# Define the distributions from group G3\n",
    "expon = lambda n: stats.expon.rvs(loc = 1, size = n)\n",
    "gamma1 = lambda n: list(np.random.gamma(2, scale = 1, size = n))\n",
    "gamma2 = lambda n: list(np.random.gamma(0.5, scale = 1, size = n))\n",
    "lognormal1 = lambda n: list(np.random.lognormal(mean = 0, sigma = 1, size = n))\n",
    "lognormal2 = lambda n: list(np.random.lognormal(mean = 0, sigma = 2, size = n))\n",
    "lognormal3 = lambda n: list(np.random.lognormal(mean = 0, sigma = 0.5, size = n))\n",
    "weibull1 = lambda n: stats.weibull_min.rvs(0.5, scale = 1, size = n)\n",
    "weibull2 = lambda n: stats.weibull_min.rvs(2, scale = 1, size = n)\n",
    "\n",
    "# Define the distributions from group G4\n",
    "uniform = lambda n: list(np.random.uniform(low = 0, high = 1, size = n))\n",
    "beta1 = lambda n: np.random.beta(2, 2, size = n)\n",
    "beta2 = lambda n: np.random.beta(0.5, 0.5, size = n)\n",
    "beta3 = lambda n: np.random.beta(4, 4, size = n)\n",
    "\n",
    "# Let groups be a dictionary containing distributions from four groups G1-G4\n",
    "groups = {\n",
    "    1 : [logistic, laplace, t1, t3],\n",
    "    2 : [gumbel1, gumbel2, gumbel3],\n",
    "    3 : [expon, gamma1, gamma2, lognormal1, lognormal2, lognormal3, weibull1, weibull2],\n",
    "    4 : [uniform, beta1, beta2, beta3, ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the set, save it and update the configuration dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T12:54:37.167282Z",
     "start_time": "2021-04-10T12:54:03.366405Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the range of sample sizes\n",
    "n_range = range(10, 101, 10)\n",
    "\n",
    "# Define L, which denotes how many samples with n elements\n",
    "# will be drawn from each group.\n",
    "L = 10000\n",
    "\n",
    "set_C = {}\n",
    "\n",
    "for g in groups:\n",
    "    # Select a group\n",
    "    group = groups[g]\n",
    "    \n",
    "    # Prepare the storage to hold the samples from this group\n",
    "    samples = []\n",
    "    \n",
    "    # Draw the samples\n",
    "    for n in n_range:\n",
    "        # Initialize the counter of the samples generated so far in this group\n",
    "        so_far = 0\n",
    "        \n",
    "        # Iterate over the distributions in the group until L samples are generated\n",
    "        d = 0\n",
    "        while so_far <= L:\n",
    "            # Get the distribution whose turn is to generate a sample\n",
    "            dist = group[d]\n",
    "            \n",
    "            # Generate a sample\n",
    "            sample = dist(n)\n",
    "            \n",
    "            # Store it\n",
    "            samples.append(sample)\n",
    "            \n",
    "            # Increase the counters\n",
    "            so_far = so_far + 1\n",
    "            d = d + 1\n",
    "            \n",
    "            # Return to the first distribution in the group and start over\n",
    "            if d == len(group):\n",
    "                d = 0\n",
    "    \n",
    "    # Label the samples as non-normal\n",
    "    samples = util.label_samples(samples, 0)\n",
    "    \n",
    "    # Describe the set\n",
    "    set_name = 'C-G{}'.format(g)\n",
    "    filename = '{}.data'.format(set_name)\n",
    "    \n",
    "    group_metadata = {\n",
    "        'name' : set_name,\n",
    "        'n_range' : n_range,\n",
    "        'number_of_normal' : 0,\n",
    "        'number_of_nonnormal' : len(samples),\n",
    "        'path' : os.path.join(data_directory_path, filename)\n",
    "    }\n",
    "\n",
    "    # Add it to the configuration dictionary\n",
    "    configuration['data']['datasets'][set_name] = group_metadata\n",
    "                \n",
    "    # Save the samples\n",
    "    path = group_metadata['path']\n",
    "    util.save_to_file(samples, path)\n",
    "    print(\"Saved {} to the file {}\".format(set_name, path))\n",
    "    \n",
    "    set_C[set_name] = samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the empirical skewness and kurtosis of the samples drawn from the four groups in set $\\mathcal{C}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T13:00:22.584817Z",
     "start_time": "2021-04-10T12:57:09.624682Z"
    }
   },
   "outputs": [],
   "source": [
    "figures['C'] = {}\n",
    "statistics = ['skewness', 'kurtosis']\n",
    "for group_name in set_C:\n",
    "    desc = inspect_dataset(set_C[group_name], statistics=statistics)\n",
    "    for label in desc:\n",
    "        if label == 0:\n",
    "            fig = plt.figure()\n",
    "            plt.scatter(desc[label][statistics[0]],\n",
    "                        desc[label][statistics[1]],\n",
    "                        alpha=0.2,\n",
    "                        color='crimson')\n",
    "            figures['C'][group_name] = fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set $\\mathcal{D}$\n",
    "\n",
    "Create it the same way as the set $\\mathcal{A}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T13:01:00.904515Z",
     "start_time": "2021-04-10T13:00:50.997849Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the ranges for the sample sizes \n",
    "# and non-normal skewness and kurtosis \n",
    "n_range = range(10, 101, 10)\n",
    "s_range = [x/10.0 for x in range(-300, 301, 5)] # skewness range -150, 151, 5;-805, 810, 5\n",
    "k_range = [x/10.0 for x in range(0, 401, 5)]   # kurtosis range 0, 201, 5;0, 1610, 5\n",
    "\n",
    "# Let M denote the number of non-normal samples drawn from the same distribution.\n",
    "# Since the set is created as balanced, M will influence the number of normal samples\n",
    "# in the set. See the function generate_dataset for details.\n",
    "M = 1\n",
    "\n",
    "# Generate and register the set\n",
    "set_D = generate_dataset(n_range, s_range, k_range, M)\n",
    "describe_and_save(set_D, 'D', n_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set $\\mathcal{E}$\n",
    "\n",
    "Create a set that contains normal samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T19:52:31.683606Z",
     "start_time": "2021-04-10T19:52:19.588501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to the file data/E.data\n"
     ]
    }
   ],
   "source": [
    "n_range = range(5, 101, 5)\n",
    "L = 10000\n",
    "\n",
    "samples = util.generate_normal_samples(n_range, L)\n",
    "\n",
    "set_E = util.label_samples(samples, 1)\n",
    "\n",
    "describe_and_save(set_E, 'E', n_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set $\\mathcal{F}$\n",
    "\n",
    "This set will contain contaminated normal samples. It will be used to test for robustness.\n",
    "\n",
    "We will create it by contaminating a sample from the standard normal $N(0, 1)$ with a small number of elements drawn from $N(\\mu, \\sigma^2)$. Each sample in set $\\mathcal{F}$ comes from a mixture of the following form:\n",
    "\n",
    "$$(1-\\varepsilon)\\underbrace{N(0, 1)}_{\\text{core}}+\\varepsilon \\underbrace{N(\\mu, \\sigma^2)}_{\\text{contaminator}}$$\n",
    "\n",
    "where we set $\\varepsilon$ to $0.05$. Depending on $\\mu$ and $\\sigma^2$, we distinguish between four types of contamination:\n",
    "- left ($\\mu = -3, \\sigma^2=1$),\n",
    "- right ($\\mu = 3, \\sigma^2=1$),\n",
    "- symmetric ($\\mu=0, \\sigma^2=6$),\n",
    "- and central ($\\mu=0, \\sigma^2=0.01$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T13:16:51.977161Z",
     "start_time": "2021-04-10T13:16:44.847773Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the contaminators\n",
    "left_contaminator = lambda m: np.random.normal(-3, 1, m).tolist()\n",
    "right_contaminator = lambda m: np.random.normal(3, 1, m).tolist()\n",
    "symmetric_contaminator = lambda m: np.random.normal(0, 6, m).tolist()\n",
    "central_contaminator = lambda m: np.random.normal(0, 0.01, m).tolist() \n",
    "\n",
    "contaminators = {\n",
    "    'left' : left_contaminator,\n",
    "    'right': right_contaminator,\n",
    "    'symmetric': symmetric_contaminator,\n",
    "    'central': central_contaminator\n",
    "}\n",
    "\n",
    "# Define how many samples of each size will be created for each contamination type.\n",
    "L = 10000\n",
    "\n",
    "# Prepare a dictionary to store the dataset\n",
    "contaminated_samples = {}\n",
    "\n",
    "# Create the dataset\n",
    "for code in contaminators:\n",
    "    contaminator = contaminators[code]\n",
    "    contaminated_samples[code] = []\n",
    "    \n",
    "    for n in range(10, 101, 10):\n",
    "        # determine the actual number of contaminated and core elements\n",
    "        n_contaminated = max(1, int(0.05 * n))\n",
    "        n_core = n - n_contaminated\n",
    "        \n",
    "        # Create L contaminated samples \n",
    "        for l in range(L):\n",
    "            # Draw the core part \n",
    "            core = np.random.normal(0, 1, n_core).tolist()\n",
    "            \n",
    "            # Draw the contaminated part\n",
    "            contamination = contaminator(n_contaminated)\n",
    "            \n",
    "            # Unify them\n",
    "            contaminated_sample = core + contamination\n",
    "            \n",
    "            # Store the sample\n",
    "            contaminated_samples[code].append(contaminated_sample)\n",
    "        \n",
    "    # Label the samples as non-normal\n",
    "    contaminated_samples[code] = util.label_samples(contaminated_samples[code], 0)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T13:31:05.658280Z",
     "start_time": "2021-04-10T13:30:49.472624Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the samples contaminated in the same way in the same file\n",
    "for x in contaminated_samples:\n",
    "    set_name = 'F-{}'.format(x)\n",
    "    path = os.path.join(data_directory_path, '{}.data'.format(set_name))\n",
    "    util.save_to_file(contaminated_samples[x], path)\n",
    "    \n",
    "    group_metadata = {\n",
    "        'name' : set_name,\n",
    "        'n_range' : range(10, 10, 101),\n",
    "        'number_of_normal' : 0,\n",
    "        'number_of_nonnormal' : len(contaminated_samples[x]),\n",
    "        'path' : path\n",
    "    }\n",
    "\n",
    "    configuration['data']['datasets'][set_name] = group_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the skewness and kurtosis of the contaminated samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T13:38:07.975309Z",
     "start_time": "2021-04-10T13:35:06.739615Z"
    }
   },
   "outputs": [],
   "source": [
    "figures['F'] = {}\n",
    "for x in contaminated_samples:\n",
    "    desc = inspect_dataset(contaminated_samples[x], statistics=['skewness', 'kurtosis'])\n",
    "\n",
    "    for label in desc:\n",
    "        if label == 0:\n",
    "            fig = plt.figure()\n",
    "            plt.scatter(desc[label]['skewness'],\n",
    "                        desc[label]['kurtosis'],\n",
    "                        alpha=0.2,\n",
    "                        color='crimson')\n",
    "            figures['F'][x] = fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set $\\mathcal{G}$\n",
    "\n",
    "Another set that is same as $\\mathcal{A}$, except that the samples have sizes $5, 10, 15, \\ldots, 100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T19:52:10.012822Z",
     "start_time": "2021-04-10T19:51:50.402355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal samples:  26100\n",
      "Non-normal samples:  26100\n",
      "Saved to the file data/G.data\n"
     ]
    }
   ],
   "source": [
    "# Define the ranges for the sample sizes \n",
    "# and non-normal skewness and kurtosis in the set A\n",
    "n_range = range(5, 101, 5) \n",
    "s_range = [x/10.0 for x in range(-300, 301, 5)] # skewness range -150, 151, 5;-805, 810, 5\n",
    "k_range = [x/10.0 for x in range(0, 401, 5)]   # kurtosis range 0, 201, 5;0, 1610, 5\n",
    "\n",
    "# Let M denote the number of non-normal samples drawn from the same distribution\n",
    "M = 1\n",
    "\n",
    "set_G = generate_dataset(n_range, s_range, k_range, M)\n",
    "describe_and_save(set_G, 'G', n_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Datasets\n",
    "\n",
    "### Set $\\mathcal{R}_{height}$\n",
    "Create the set that will contain the samples of heights from a larger set of heights. The original data were taken from https://github.com/rmcelreath/rethinking/blob/master/data/Howell1.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T13:45:39.158108Z",
     "start_time": "2021-04-10T13:45:39.014543Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('data/Howell1.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both sexes and each age window from $[18, 27], [19, 28]$ to $[79, 88]$, extract the corresponding heights from the original data and form a new sample of heights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T13:46:53.580370Z",
     "start_time": "2021-04-10T13:46:53.152007Z"
    }
   },
   "outputs": [],
   "source": [
    "figs = {}\n",
    "sex = ['female', 'male']\n",
    "\n",
    "age_limits = [(x, x + 9) for x in range(18, 80)]\n",
    "\n",
    "samples = {}\n",
    "\n",
    "for male in [0, 1]:\n",
    "    for (min_age, max_age) in age_limits:\n",
    "        mask = (df['male'] == male) & (df['age'] >= min_age) & (df['age'] < max_age)\n",
    "        \n",
    "        heights = list(df[mask]['height'].values)\n",
    "        samples[(male, min_age, max_age)] = heights\n",
    "        n = len(heights)\n",
    "        \n",
    "        description = df[mask]['height'].describe()\n",
    "        m = description['mean']\n",
    "        s = description['std']\n",
    "        \n",
    "        #fig = plt.figure(figsize=(10, 7))\n",
    "        \n",
    "        #divergences = []\n",
    "\n",
    "        for i in range(100):\n",
    "            random_sample = np.random.normal(m, s, n)\n",
    "            #density = stats.gaussian_kde(random_sample)\n",
    "            #divergence = stats.entropy(heights, random_sample)\n",
    "            #divergences.append(divergence)\n",
    "    \n",
    "            random_sample.sort()\n",
    "            #plt.hist(random_sample, bins=10, color='lavender', density=True, cumulative=True,\n",
    "            #          histtype='step', linewidth=3)\n",
    "\n",
    "        #plt.hist(heights, bins=10, color='navy', density=True, cumulative=True, histtype='step', linewidth=3)\n",
    " \n",
    "        #legend_objects = [Line2D([0], [0], color='navy', lw=3), Line2D([0], [0], color='lavender', lw=3)]\n",
    "        #plt.legend(legend_objects, ['Original EDF', 'Simulated EDFs'], fontsize=13, loc='upper left')\n",
    "        #plt.xlabel('Height (cm)')\n",
    "        #figs[(male, min_age, max_age)] = fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T13:46:54.336133Z",
     "start_time": "2021-04-10T13:46:54.327254Z"
    }
   },
   "outputs": [],
   "source": [
    "# Label samples as normal and save them\n",
    "samples = util.label_samples(list(samples.values()), 1)\n",
    "\n",
    "describe_and_save(samples, 'R_height', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T13:46:55.374301Z",
     "start_time": "2021-04-10T13:46:55.365363Z"
    }
   },
   "outputs": [],
   "source": [
    "figs = {'{}_{}_{}_fig'.format(*key) : figs[key] for key in figs}\n",
    "\n",
    "traverse_and_save({ 'data' : {'R_height' : figs}},\n",
    "                  configuration['reports']['directory_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set $\\mathcal{R}_{earthquake}$\n",
    "\n",
    "The original data were taken from http://socr.ucla.edu/docs/resources/SOCR_Data/SOCR_Data_Earthquakes_Over3.html ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T13:46:59.343823Z",
     "start_time": "2021-04-10T13:46:59.017238Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('data/earthquakes.csv', header=0, parse_dates=[0], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T13:47:00.420900Z",
     "start_time": "2021-04-10T13:47:00.149688Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T13:47:02.575590Z",
     "start_time": "2021-04-10T13:47:01.038825Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the density of the magnitudes\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "df['Mag'].plot.density(linewidth=3, color='navy')\n",
    "plt.xlabel('Magnitude')\n",
    "traverse_and_save({ 'data' : {'R_earthquake' : {'magnitude_density_fig' : fig}}},\n",
    "                  configuration['reports']['directory_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T13:47:25.616483Z",
     "start_time": "2021-04-10T13:47:02.577378Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sample from the density (which is clearly not normal)\n",
    "# to create a number of non-normal samples\n",
    "\n",
    "samples = []\n",
    "\n",
    "n_range = range(5, 101, 5)\n",
    "\n",
    "for n in n_range:\n",
    "    for i in range(1000):\n",
    "        sample = list(df.sample(n=n)['Mag'].values)\n",
    "        samples.append(sample)\n",
    "        \n",
    "# Label the samples as non-normal\n",
    "samples = util.label_samples(samples, 0)\n",
    "\n",
    "# Save them\n",
    "describe_and_save(samples, 'R_earthquake', n_range)\n",
    "\n",
    "# Plot the samples' skewness and kurtosis\n",
    "desc = inspect_dataset(samples)\n",
    "plot_skewness_and_kurtosis(desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Inspect $G_4$ and $\\mathcal{F}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T13:47:26.481104Z",
     "start_time": "2021-04-10T13:47:25.618292Z"
    }
   },
   "outputs": [],
   "source": [
    "G4 = util.separate_by_size(set_C['C-G4'])\n",
    "\n",
    "F = {code: util.separate_by_size(contaminated_samples[code]) for code in contaminated_samples}\n",
    "\n",
    "E = util.separate_by_size(set_E)\n",
    "\n",
    "D = util.separate_by_label_and_size(set_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $G_4$ vs $\\mathcal{E}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T11:12:44.330705Z",
     "start_time": "2021-04-10T11:12:44.324361Z"
    }
   },
   "outputs": [],
   "source": [
    "figures['G4-E'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T11:12:57.708491Z",
     "start_time": "2021-04-10T11:12:44.663699Z"
    }
   },
   "outputs": [],
   "source": [
    "for n in G4.keys():\n",
    "    g4_subgroup = G4[n]\n",
    "    g4_desc = inspect_dataset(g4_subgroup, statistics=['rs', 'rk'])\n",
    "    \n",
    "    e_subgroup = E[n]\n",
    "    e_desc = inspect_dataset(e_subgroup, statistics=['rs', 'rk'])\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    plt.scatter(g4_desc[0]['rs'],\n",
    "                g4_desc[0]['rk'],\n",
    "                alpha=0.2,\n",
    "                label='Non-normal',\n",
    "                color='crimson')\n",
    "    \n",
    "    plt.scatter(e_desc[1]['rs'],\n",
    "                e_desc[1]['rk'],\n",
    "                alpha=0.2,\n",
    "                label='Normal',\n",
    "                color='navy')\n",
    "    plt.legend()\n",
    "    \n",
    "    figures['G4-E'][n-1] = fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $G_4$ vs Non-normal Subset of $\\mathcal{D}$ vs $\\mathcal{E}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T11:16:51.816096Z",
     "start_time": "2021-04-10T11:16:43.503505Z"
    }
   },
   "outputs": [],
   "source": [
    "statistics = ['mad', 'sd']\n",
    "\n",
    "figures['G4-D0'] = {}\n",
    "for n in G4.keys():\n",
    "    g4_subgroup = G4[n]\n",
    "    g4_desc = inspect_dataset(g4_subgroup, statistics=statistics)\n",
    "    \n",
    "    d_subgroup = D[0][n - 1]\n",
    "    d_desc = inspect_dataset(d_subgroup, \n",
    "                             labels=[0 for _ in range(len(d_subgroup))],\n",
    "                             statistics=statistics)\n",
    "    \n",
    "    e_subgroup = E[n]\n",
    "    e_desc = inspect_dataset(e_subgroup, statistics=statistics)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    plt.scatter(g4_desc[0]['skewness'],\n",
    "                g4_desc[0]['kurtosis'],\n",
    "                alpha=0.2,\n",
    "                label='$G_4$',\n",
    "                color='crimson')\n",
    "    \n",
    "    plt.scatter(d_desc[0]['skewness'],\n",
    "                d_desc[0]['kurtosis'],\n",
    "                alpha=0.2,\n",
    "                label='Training non-normal',\n",
    "                color='purple')\n",
    "    \n",
    "    plt.scatter(e_desc[1]['skewness'],\n",
    "                e_desc[1]['kurtosis'],\n",
    "                alpha=0.2,\n",
    "                label='Normal',\n",
    "                color='navy')\n",
    "    \n",
    "    #plt.ylim(0, 7)\n",
    "    #plt.xlim(-3, 3)\n",
    "    plt.legend()\n",
    "    \n",
    "    figures['G4-D0'][n-1] = fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T18:54:45.453945Z",
     "start_time": "2021-04-09T18:54:45.440010Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\mathcal{F}$ vs $\\mathcal{E}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T16:11:39.744521Z",
     "start_time": "2021-04-09T16:11:39.739118Z"
    }
   },
   "outputs": [],
   "source": [
    "figures['F-E'] = {code : {} for code in F}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T16:14:06.866764Z",
     "start_time": "2021-04-09T16:13:34.360688Z"
    }
   },
   "outputs": [],
   "source": [
    "for code in F:\n",
    "    for n in F[code].keys():\n",
    "        f_subgroup = F[code][n]\n",
    "        f_desc = inspect_dataset(f_subgroup)\n",
    "    \n",
    "        e_subgroup = E[n]\n",
    "        e_desc = inspect_dataset(e_subgroup)\n",
    "    \n",
    "        fig = plt.figure(figsize=(10, 4))\n",
    "    \n",
    "        plt.scatter(f_desc[0]['skewness'],\n",
    "                    f_desc[0]['kurtosis'],\n",
    "                    alpha=0.2,\n",
    "                    label=code + ' contamination',\n",
    "                    color='crimson')\n",
    "    \n",
    "        plt.scatter(e_desc[1]['skewness'],\n",
    "                    e_desc[1]['kurtosis'],\n",
    "                    alpha=0.2,\n",
    "                    label='Normal',\n",
    "                    color='navy')\n",
    "        plt.legend()\n",
    "        plt.title(f'$n={n-1}$')\n",
    "    \n",
    "        figures['F-E'][code][n-1] = fig\n",
    "    \n",
    "    #fig.suptitle(f'$n={n - 1}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the figures and changes to the configuration dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T19:53:38.433700Z",
     "start_time": "2021-04-10T19:53:38.422573Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the updates to the configuration dictionary\n",
    "with open(config_path, 'wb') as f:\n",
    "    pickle.dump(configuration, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T14:18:12.253751Z",
     "start_time": "2021-04-10T14:17:52.589589Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the figures\n",
    "def save_figures(path, dictionary):\n",
    "    if type(dictionary) is not dict:\n",
    "        figure = dictionary\n",
    "        \n",
    "        path +=  '.pdf'\n",
    "        \n",
    "        if 'savefig' in dir(figure):\n",
    "            figure.savefig(path, bbox_inches='tight')\n",
    "        else:\n",
    "            figure.figure.savefig(path, bbox_inches='tight')\n",
    "    else:\n",
    "        for key in dictionary:\n",
    "            save_figures(path + '_' + str(key), dictionary[key])\n",
    "\n",
    "save_figures(configuration['reports']['directory_path'], {'data' : figures})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3normal",
   "language": "python",
   "name": "p3normal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
