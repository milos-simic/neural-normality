{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistic-Based Neural Network for Normality Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:34:53.762190Z",
     "start_time": "2020-09-23T23:34:43.462352Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import everything that's needed to run the notebook\n",
    "import os\n",
    "import pickle\n",
    "import pathlib\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from IPython.display import display, Markdown, Latex\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics\n",
    "import sklearn.preprocessing\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import boruta\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:34:53.783687Z",
     "start_time": "2020-09-23T23:34:53.763815Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the path to the configuration dictionary\n",
    "config_path = 'configuration.p'\n",
    "\n",
    "# Load the configuration dictionary\n",
    "with open(config_path, 'rb') as f:\n",
    "    configuration = pickle.load(f)\n",
    "    \n",
    "# Get the paths to the relevant directories \n",
    "data_directory_path = configuration['data']['directory_path']\n",
    "classifiers_directory_path = configuration['classifiers']['directory_path']\n",
    "\n",
    "# Get the parameters of the experiment\n",
    "cv_folds = configuration['experiment']['number_of_cv_folds']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "Load the datasets using the function `load_from_file` from `util`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:35:13.108089Z",
     "start_time": "2020-09-23T23:34:53.785247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading A from data/A.data\n",
      "Done.\n",
      "Loading B from data/B.data\n",
      "Done.\n",
      "Loading C-G1 from data/C-G1.data\n",
      "Done.\n",
      "Loading C-G2 from data/C-G2.data\n",
      "Done.\n",
      "Loading C-G3 from data/C-G3.data\n",
      "Done.\n",
      "Loading C-G4 from data/C-G4.data\n",
      "Done.\n",
      "Loading D from data/D.data\n",
      "Done.\n",
      "Loading E from data/E.data\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Define the dictionary to store the actual datasets, indexed by their names\n",
    "datasets = {}\n",
    "\n",
    "# Load the datasets\n",
    "for set_name in configuration['data']['datasets']:\n",
    "    set_path = configuration['data']['datasets'][set_name]['path']\n",
    "    print('Loading {} from {}'.format(set_name, set_path))\n",
    "    datasets[set_name] = util.load_from_file(set_path)\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a normal sample from the dataset $\\mathcal{A}$. and a non-normal from the group $G_1$ of the dataset $\\mathcal{C}$. The normal samples are labeled with $1$, whereas the label of each non-normal one is $0$. The normal samples constitute the \"positive\" and the non-normal the \"negative\" class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:35:13.115389Z",
     "start_time": "2020-09-23T23:35:13.111704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A normal sample (ending in 1):\n",
      " [-45.49063028459169, -30.981143033573673, -13.728309265861695, -15.666454590679104, -36.22767976281412, -11.508188107883877, -24.221912056880065, -39.437369899085894, -36.34343338555324, -15.150388381158336, 1.0]\n",
      "A non-normal sample (ending in 0):\n",
      " [0.3274030780949263, 2.1201516653169254, -1.0689942361628708, -0.9340489803307244, 0.3370605169731828, 1.5370159253341324, 0.8311764716162305, -0.17301152203223455, -2.434902734249694, -5.060191877248404, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print('A normal sample (ending in 1):\\n', datasets['A'][0])\n",
    "print('A non-normal sample (ending in 0):\\n', datasets['C-G1'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split $\\mathcal{A}$ into Cross-validation and Test  Subsets ($\\mathcal{A}_{cv}$ and $\\mathcal{A}_{test}$) \n",
    "\n",
    "Split $\\mathcal{A}$ into the subsets for cross-validation ($\\mathcal{A}_{cv})$ and testing ($\\mathcal{A}_{test}$).\n",
    "\n",
    "Use 70% of the set to cross-validate and 30% for subsequent testing and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:35:13.383635Z",
     "start_time": "2020-09-23T23:35:13.117001Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the labels from the set, leaving only samples in it\n",
    "labels = [labeled_sample.pop() for labeled_sample in datasets['A']]\n",
    "samples = datasets['A']\n",
    "\n",
    "# There is no need to store the sama data twice, in datasets['A'] and in (samples, labels)\n",
    "del datasets['A']\n",
    "\n",
    "# Define the stratification labels as the combination of actual labels and sample sizes\n",
    "stratification_labels = [str(label) + str(len(sample)) for (label, sample) in zip(labels, samples)]\n",
    "\n",
    "# Set the relative size of the CV subset\n",
    "train_size = 0.7\n",
    "\n",
    "# Split the data into CV and test subsets\n",
    "set_A_cv, set_A_test, y_cv, y_test = train_test_split(samples, labels, stratify=stratification_labels, \n",
    "                                              train_size=train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Labels and the Samples in Other Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:35:13.506593Z",
     "start_time": "2020-09-23T23:35:13.384841Z"
    }
   },
   "outputs": [],
   "source": [
    "for set_name in datasets:\n",
    "    labels = [sample.pop() for sample in datasets[set_name]]\n",
    "    samples = datasets[set_name]\n",
    "    \n",
    "    datasets[set_name] = {'samples' : samples, 'labels' : labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the Statistic-based Feedforward Neural Network Classifier (SBNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:35:13.535038Z",
     "start_time": "2020-09-23T23:35:13.508306Z"
    }
   },
   "outputs": [],
   "source": [
    "def lin_mudholkar_statistic(sample, tol=1e-7):\n",
    "    n = len(sample)\n",
    "    sum_of_squares = 0\n",
    "    for x in sample:\n",
    "        sum_of_squares = sum_of_squares + x**2\n",
    "        \n",
    "    h_values = [0 for i in range(n)]\n",
    "    for i in range(n):\n",
    "        x = sample[i]\n",
    "        \n",
    "        corrected_sum = 0\n",
    "        for j in range(n):\n",
    "            if j != i:\n",
    "                corrected_sum = corrected_sum + sample[j]\n",
    "                \n",
    "        square_of_sum = corrected_sum**2\n",
    "        difference = (((sum_of_squares - x**2) - square_of_sum / (n - 1)) / n)\n",
    "        if abs(difference) <= tol:\n",
    "            difference = 0\n",
    "        h_i = difference**(1/3)\n",
    "        h_values[i] = h_i\n",
    "        \n",
    "        #print(i, x, corrected_sum, square_of_sum, square_of_sum / (n - 1), '\\n', h_i)\n",
    "    \n",
    "    r = np.corrcoef(sample, h_values)\n",
    "    \n",
    "    return np.arctan(r[0, 1])\n",
    "\n",
    "def vasicek_statistic(sample, m=3):\n",
    "    n = len(sample)\n",
    "    sample = np.array(sample, dtype=np.float64)\n",
    "    sd = np.std(sample)\n",
    "    sorted_sample = np.sort(sample)\n",
    "    product = 1\n",
    "    m = m\n",
    "    for i in range(n):\n",
    "        if i - m < 0:\n",
    "            left = sorted_sample[0]\n",
    "        else:\n",
    "            left = sorted_sample[i - m]\n",
    "        \n",
    "        if i + m > n - 1:\n",
    "            right = sorted_sample[n - 1]\n",
    "        else:\n",
    "            right = sorted_sample[i + m]\n",
    "        \n",
    "        product = product * (right - left)\n",
    "    \n",
    "    return (n / (2 * m * sd)) * (product ** (1 / n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:35:13.622376Z",
     "start_time": "2020-09-23T23:35:13.537396Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(sample):\n",
    "    n = len(sample)\n",
    "    skewness = scipy.stats.skew(sample)\n",
    "    kurtosis = scipy.stats.kurtosis(sample, fisher=False)\n",
    "    W = scipy.stats.shapiro(sample).statistic\n",
    "    lm_stat = lin_mudholkar_statistic(sample)\n",
    "    K3 = vasicek_statistic(sample, m=3)\n",
    "    K5 = vasicek_statistic(sample, m=5)\n",
    "    return [skewness, kurtosis, W, lm_stat, K3, K5, n]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:35:13.704608Z",
     "start_time": "2020-09-23T23:35:13.626785Z"
    }
   },
   "outputs": [],
   "source": [
    "class SBNNPreprocessor(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        super(SBNNPreprocessor, self).__init__()\n",
    "        \n",
    "        # Set the names of the features in the descriptors\n",
    "        self.features = ['skewness', 'kurtosis', 'W', 'LN-statistic', 'K3', 'K5', 'n']\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Not needed, but present for compatibility.\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Note: Currently working only on a list of lists or a single list.\n",
    "        if isinstance(X, list):\n",
    "            if all(isinstance(x, list) for x in X):\n",
    "                X = [preprocess(x) for x in X]\n",
    "                return pd.DataFrame(X)\n",
    "            else:\n",
    "                X = preprocess(X)\n",
    "                return X\n",
    "        else:\n",
    "            # Pandas dataframes and numpy arrays are not supported for now.\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validate\n",
    "Create a `sklearn` pipeline that consists of the preprocessor, standard scaler, mean imputer to replace the null values, and the neural network itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:35:13.791631Z",
     "start_time": "2020-09-23T23:35:13.706068Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = SBNNPreprocessor()\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "neural_net = MLPClassifier(solver='adam', max_iter=200, activation='relu',\n",
    "                           early_stopping=True, validation_fraction=0.1)\n",
    "pipe = Pipeline([('preprocessor', preprocessor),\n",
    "                 ('scaler', scaler),\n",
    "                 ('imputer', imputer),\n",
    "                 ('neural_net', neural_net),\n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the grid search to fit the network's parameters and find the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:41:03.198095Z",
     "start_time": "2020-09-23T23:35:13.796169Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  5.3min finished\n",
      "/home/milos/statisticka_klasifikacija/p3/lib/python3.6/site-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/milos/statisticka_klasifikacija/p3/lib/python3.6/site-packages/numpy/lib/function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/home/milos/statisticka_klasifikacija/p3/lib/python3.6/site-packages/scipy/stats/morestats.py:1678: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "/home/milos/statisticka_klasifikacija/p3/lib/python3.6/site-packages/ipykernel_launcher.py:49: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/home/milos/statisticka_klasifikacija/p3/lib/python3.6/site-packages/ipykernel_launcher.py:49: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor', SBNNPreprocessor()),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('imputer', SimpleImputer()),\n",
       "                                       ('neural_net',\n",
       "                                        MLPClassifier(early_stopping=True))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'neural_net__alpha': [10, 1, 0.1],\n",
       "                         'neural_net__hidden_layer_sizes': [1000, (100, 10)]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the hyperparameter grid\n",
    "param_grid = dict(\n",
    "                  neural_net__hidden_layer_sizes = [(1000), (100, 10)],\n",
    "                  neural_net__alpha = [10, 1, 0.1],\n",
    "                 )\n",
    "\n",
    "# Define the grid search object\n",
    "grid = GridSearchCV(pipe,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='accuracy',\n",
    "                    refit=True,\n",
    "                    cv=cv_folds,\n",
    "                    verbose=1,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "# Perform cross-validation\n",
    "grid.fit(set_A_cv, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:41:09.074343Z",
     "start_time": "2020-09-23T23:41:09.066730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neural_net__alpha': 0.1, 'neural_net__hidden_layer_sizes': 1000}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the trained network.\n",
    "sbnn = grid.best_estimator_\n",
    "\n",
    "# Show its hyperparameters\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:41:13.681471Z",
     "start_time": "2020-09-23T23:41:13.276286Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structure</th>\n",
       "      <th>c</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>score_sd</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>time_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.798686</td>\n",
       "      <td>0.006201</td>\n",
       "      <td>62.155047</td>\n",
       "      <td>10.344608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(100, 10)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.804598</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>51.806245</td>\n",
       "      <td>1.762312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844773</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>83.611160</td>\n",
       "      <td>9.960311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(100, 10)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.845375</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>60.473763</td>\n",
       "      <td>4.440777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.847345</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>82.400459</td>\n",
       "      <td>8.900024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(100, 10)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.844882</td>\n",
       "      <td>0.004238</td>\n",
       "      <td>43.775766</td>\n",
       "      <td>10.624519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   structure     c  mean_score  score_sd  mean_time    time_sd\n",
       "0       1000  10.0    0.798686  0.006201  62.155047  10.344608\n",
       "1  (100, 10)  10.0    0.804598  0.004932  51.806245   1.762312\n",
       "2       1000   1.0    0.844773  0.003468  83.611160   9.960311\n",
       "3  (100, 10)   1.0    0.845375  0.003307  60.473763   4.440777\n",
       "4       1000   0.1    0.847345  0.004148  82.400459   8.900024\n",
       "5  (100, 10)   0.1    0.844882  0.004238  43.775766  10.624519"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the means and deviations of the score(s) and CV time\n",
    "params = grid.cv_results_['params']\n",
    "mean_scores = grid.cv_results_['mean_test_score']\n",
    "score_sds = grid.cv_results_['std_test_score']\n",
    "mean_fit_times = grid.cv_results_['mean_fit_time']\n",
    "time_sds = grid.cv_results_['std_fit_time']\n",
    "\n",
    "results = []\n",
    "for (params, mean_score, score_sd, mean_fit_time, time_sd) in zip(params, mean_scores, score_sds, mean_fit_times, time_sds):\n",
    "    alpha = params['neural_net__alpha']\n",
    "    structure = params['neural_net__hidden_layer_sizes']\n",
    "    results.append([str(structure), alpha, mean_score, score_sd, mean_fit_time, time_sd])\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = ['structure', 'c', 'mean_score', 'score_sd', 'mean_time', 'time_sd']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the SBNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:42:34.225519Z",
     "start_time": "2020-09-23T23:42:34.155761Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(classifiers_directory_path + '/sbnn.p', 'wb') as f:\n",
    "    pickle.dump(sbnn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3normal",
   "language": "python",
   "name": "p3normal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "247.067px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
